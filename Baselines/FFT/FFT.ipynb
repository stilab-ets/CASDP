{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import copy \n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from autospearman import * \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "#from hypopt import GridSearch\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from fasttrees.fasttrees import FastFrugalTreeClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#from sklearn.model_selection import GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Globals\n",
    "DATA_PATH = 'C:/Users/Motaz/Desktop/work/IAC_defect_prediction'\n",
    "EXPERIMENT_NAME = 'new_data'\n",
    "EXPERIMENT_DATA_PATH = os.path.join(DATA_PATH, EXPERIMENT_NAME)\n",
    "RESULTS_PATH = './results_IAC'\n",
    "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
    "\n",
    "FEATURES =\n",
    "\n",
    "[\n",
    "    'Exp', 'LHereDocs', 'DeprFunc','ExplResrDep', 'isTerraform',\n",
    "    'numImplicitDependentEach', 'CompOpers', 'Nloc', 'Strs', 'ElemTups', 'TmpExpr', 'DynBlc', 'Lps', 'LogiOpers',\n",
    "    'isResource', 'numTokens', 'Loc', 'SuffStr', 'isModule', 'ImplDepResr', 'isData', 'NetBlc', 'ImplDepProviders', \n",
    "    'FnCall', 'LtrExpr', 'sumMccabeCC', 'Vars', 'MetaArgs', 'Attrs', 'LookUpFunc', 'ElemObjs', 'Tups', 'TextEntropy',\n",
    "    'block_identifiers', 'ImplDepLocals', 'Refs', 'EmptStr', 'Dept', 'DebugFunc', 'HereDocs', 'sumLengthStringValues',\n",
    "    'Objs', 'ImplDepData', 'Params', 'IndexAccess', 'MOpers', 'ImplDepVars', 'ImplDepModules', 'isProvider',\n",
    "    'SplatExpr', 'StarStr', 'Conds', 'isLocals', 'isOutput', 'isVariable','Ndevs', 'NChanges', 'Owner',\n",
    "    'Rexp', 'Sexp', 'Bexp', 'Age', 'RecentAge', 'num_defects_before', 'SimilarChange', 'KindExperience',\n",
    "    'Nuc', 'EditDistance', 'La', 'Ld', 'Churn', 'BbChange', 'NLa', 'NLd', 'NChurn', 'DLa', 'Dld',\n",
    "    'isAddDefault', 'isDelDefault', 'isAddType', 'isDelType', 'isAddValue', 'isDelValue', 'isAddVersion',\n",
    "    'isDelVersion', 'additions_contains_description_change', 'deletions_contains_description_change',\n",
    "    'additions_contains_meta_args_change', 'deletions_contains_meta_args_change', 'CompOpers_delta',\n",
    "    'Conds_delta', 'LogiOpers_delta', 'DynBlc_delta', 'NetBlc_delta', 'FnCall_delta', 'Params_delta', 'HereDocs_delta',\n",
    "    'LHereDocs_delta','IndexAccess_delta', 'LtrExpr_delta', 'Strs_delta', 'sumLengthStringValues_delta', 'Lps_delta',\n",
    "    'MOpers_delta', 'sumMccabeCC_delta', 'MetaArgs_delta', 'Objs_delta', 'ElemObjs_delta', 'Refs_delta',\n",
    "    \"Vars_delta\", '_delta' ,'SplatExpr_delta' ,'textEntropyMeasure_delta', 'TmpExpr_delta', 'Tups_delta',\n",
    "    'ElemTups_delta', 'Dept_delta', 'Loc_delta', 'Nloc_delta', 'Attrs_delta', 'numResourceDependency_delta',\n",
    "    'ImplDepResr_delta', 'ImplDepData_delta', 'ImplDepModules_delta', 'ImplDepProviders_delta',\n",
    "    'ImplDepLocals_delta', 'ImplDepVars_delta', 'numImplicitDependentEach_delta', 'EmptStr_delta',\n",
    "    'SuffStr_delta','StarStr_delta','numDebuggingFunctions_delta','DeprFunc_delta','ExplResrDep_delta'\n",
    "]\n",
    "TARGET = 'RealBug'\n",
    "APPLY_SMOTE = True\n",
    "TUNE=True\n",
    "FINAL_RESULTS_PATH = '../results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(EXPERIMENT_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, 'aws-observability__terraform-aws-observability-accelerator_long_val_train.csv'))\n",
    "for col in pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, 'aws-observability__terraform-aws-observability-accelerator_long_val_train.csv')).columns:\n",
    "    print(col)\n",
    "    print(a[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers \n",
    "def remove_constant_features(df, features):\n",
    "    # Create a VarianceThreshold instance with the specified threshold\n",
    "    selector = VarianceThreshold(threshold=0.0)\n",
    "\n",
    "    # Separate the target feature from the other features\n",
    "    X = df[features]\n",
    "\n",
    "    # Fit the selector to the features (this computes the variances)\n",
    "    selected_features_indices = selector.fit(X).get_support(indices=True)\n",
    "\n",
    "    return X.iloc[:, selected_features_indices]\n",
    "\n",
    "def evaluate_model_predictions(y_true, y_pred, y_prob): \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "\n",
    "    res ={\n",
    "        'MCC':matthews_corrcoef(y_true, y_pred),\n",
    "        'G' : geometric_mean_score(y_true, y_pred), \n",
    "        'f1' : f1_score(y_true, y_pred),\n",
    "        'tpr': recall_score(y_true, y_pred, pos_label=1),\n",
    "        'tnr' : recall_score(y_true, y_pred,pos_label=0),\n",
    "        'precision': precision_score(y_true, y_pred), \n",
    "        'fpr': 1 - recall_score(y_true, y_pred,pos_label=0),\n",
    "        'fnr': 1 - recall_score(y_true, y_pred,pos_label=1),\n",
    "        'tp' : tp, \n",
    "        'tn': tn, \n",
    "        'fp': fp, \n",
    "        'fn': fn\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dist2heaven(y_true, y_pred): \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    tpr = tp/(tp + fn)\n",
    "    fpr = fp/(fp + tn)\n",
    "    return -np.sqrt(((1 - tpr)**2 + fpr**2)*0.5)\n",
    "\n",
    "def MCC_TIMES_G(y_true, y_pred): \n",
    "    mcc = matthews_corrcoef(y_pred=y_pred, y_true=y_true)\n",
    "    g = geometric_mean_score(y_pred=y_pred, y_true=y_true)\n",
    "    return (mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_new_data = '../data/Dataset'\n",
    "results_SMOTE = []\n",
    "for apply_smote in [False]:\n",
    "    for filename in os.listdir(EXPERIMENT_DATA_PATH): \n",
    "        for run in range(1):\n",
    "            \n",
    "            if not ('train' in filename) : \n",
    "                continue\n",
    "            if apply_smote:\n",
    "                print('Applying SMOTE...')\n",
    "            if not('.csv' in filename): \n",
    "                continue\n",
    "            print('Working on file:', filename)\n",
    "            project_dir_name = os.path.join(path_new_data, filename.replace('.csv', ''))\n",
    "            os.makedirs(project_dir_name, exist_ok=True)\n",
    "\n",
    "            train_data = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, filename))\n",
    "            test_data = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, filename.replace('train', 'test')))\n",
    "\n",
    "            train_data= train_data[train_data['isTerraform']==0]\n",
    "            test_data= test_data[test_data['isTerraform']==0]\n",
    "\n",
    "            train_data_GP = train_data[FEATURES + [TARGET]].astype('float64')\n",
    "            test_data_GP = test_data[FEATURES + [TARGET]].astype('float64')\n",
    "            train_data_GP.to_csv(os.path.join(project_dir_name, filename), index=False)\n",
    "            test_data_GP.to_csv(os.path.join(project_dir_name, filename.replace('train', 'test')), index=False)\n",
    "\n",
    "\n",
    "            X_train, y_train = train_data[FEATURES], train_data[TARGET]\n",
    "            if apply_smote:\n",
    "                sm = SMOTE()\n",
    "                X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "            X_test, y_test = test_data[FEATURES], test_data[TARGET]\n",
    "            #X_train = remove_constant_features(X_train, features=FEATURES)\n",
    "            #X_train = AutoSpearman(X_train, correlation_threshold=0.7, correlation_method='spearman', VIF_threshold=5)\n",
    "            final_cols = X_train.columns\n",
    "            print('final features for', filename)\n",
    "            for col in final_cols: \n",
    "                print(f'cols.put({col}, 1);')\n",
    "            X_test = test_data[final_cols]\n",
    "            fc = FastFrugalTreeClassifier(scorer=dist2heaven)\n",
    "            fc.fit(X_train, y_train)\n",
    "            print(fc.get_tree(decision_view = False))\n",
    "            y_pred = fc.predict(X_test)\n",
    "            y_pred_train = fc.predict(X_train)\n",
    "            train_data['FFT_prediction'] = y_pred_train.astype(float)\n",
    "            test_data['FFT_prediction'] = y_pred.astype(float)\n",
    "            #train_data.to_csv(os.path.join(path_new_data, filename), index=False)\n",
    "            #test_data.to_csv(os.path.join(path_new_data, filename.replace('train', 'test')), index=False)\n",
    "            print(fc.all_trees)\n",
    "            #print('best tree idx:', fc.best_tree)\n",
    "            print('MCC:',matthews_corrcoef(y_test, y_pred))\n",
    "            print('F1:',f1_score(y_test, y_pred))\n",
    "            print('G:',geometric_mean_score(y_test, y_pred))\n",
    "\n",
    "            print('MCC train:',matthews_corrcoef(y_train, y_pred_train))\n",
    "            print('F1 train:',f1_score(y_train, y_pred_train))\n",
    "            print('G train:',geometric_mean_score(y_train, y_pred_train))\n",
    "            model_name = 'FFT'\n",
    "            if apply_smote:\n",
    "                model_name += '_SMOTE'\n",
    "            results_SMOTE.append({\n",
    "                'file_id': filename, \n",
    "                'model_id': model_name,\n",
    "                'run_id': run, \n",
    "                'MCC': matthews_corrcoef(y_test, y_pred), \n",
    "                'G': geometric_mean_score(y_test, y_pred),\n",
    "                'F1': f1_score(y_test, y_pred),\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = pd.DataFrame(results_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc.to_csv(\"IAC_FFT_MCC_without_noise.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_smote = abc[abc['model_id'] == 'FFT_SMOTE']\n",
    "fft_ns = abc[abc['model_id'] == 'FFT']\n",
    "fft_smote['model_id'] = 'FFT'\n",
    "fft_smote.to_csv('FFT_SMOTE.csv', index=False)\n",
    "fft_ns.to_csv('FFT.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc.to_csv('FFT.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc['file_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc['MCC'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_FEATURES = ['numTuples', 'numElemTuples_delta', 'rexp', 'numFunctionCall_delta',\n",
    "       'numEmptyString_delta', 'numExplicitResourceDependency_delta',\n",
    "       'numLinesHereDocs_delta', 'isModule', 'exp', 'numObjects_delta',\n",
    "       'additions_diffusion', 'num_defects_before',\n",
    "       'numImplicitDependentModules_delta', 'numMathOperations_delta',\n",
    "       'numDeprecatedFunctions_delta', 'numMetaArg_delta',\n",
    "       'numConditions_delta', 'numImplicitDependentResources_delta',\n",
    "       'numImplicitDependentProviders', 'deletions_contains_versioning_change',\n",
    "       'num_unique_change', 'numImplicitDependentLocals_delta',\n",
    "       'numIndexAccess_delta', 'additions_contains_value_output_change',\n",
    "       'numComparisonOperators_delta', 'additions_contains_versioning_change',\n",
    "       'deletions_contains_value_output_change', 'numLogiOpers', 'isProvider',\n",
    "       'numExplicitResourceDependency', 'isResource',\n",
    "       'numSplatExpressions_delta', 'isLocals', 'code_ownership',\n",
    "       'numDynamicBlocks_delta', 'num_same_instances_changed_before',\n",
    "       'nloc_delta', 'kexp', 'numLoops',\n",
    "       'additions_contains_default_change', 'additions_contains_type_change',\n",
    "       'deletions_contains_default_change', 'deletions_contains_type_change',\n",
    "       'numImplicitDependentVars_delta', 'numImplicitDependentProviders_delta',\n",
    "       'deletions_lines_normalized', 'numImplicitDependentData_delta',\n",
    "       'containDescriptionField', 'textEntropyMeasure', 'additions_normalized',\n",
    "       'numNestedBlocks_delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studied_file = 'CDCgov__prime-simplereport_train.csv'\n",
    "train_data = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, studied_file))\n",
    "test_data = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, studied_file.replace('train', 'test')))\n",
    "\n",
    "for feature in SELECTED_FEATURES: \n",
    "    best_threshold = feature\n",
    "    best_val = -2 \n",
    "    val_val = -2 \n",
    "    quantiles  = train_data[feature].quantile([i/100 for i in range(0, 101)])#train_data[feature].unique()\n",
    "    for quantile in quantiles: \n",
    "        \n",
    "        y_pred = (train_data[feature] > quantile).astype(int)\n",
    "        mcc_score = f1_score(y_pred=y_pred, y_true=train_data[TARGET])\n",
    "        \n",
    "        if mcc_score > best_val: \n",
    "            best_val = mcc_score\n",
    "            best_threshold = f'this.rules.add(new Greater_than_threshold(\"{feature}\", -1.0, -1.0, {float(quantile)}, 0));'\n",
    "            y_val = (test_data[feature] > quantile).astype(int)\n",
    "            val_val = f1_score(y_pred=y_val, y_true=test_data[TARGET])\n",
    "        \n",
    "        y_pred = (train_data[feature] < quantile).astype(int)\n",
    "        mcc_score = f1_score(y_pred=y_pred, y_true=train_data[TARGET])\n",
    "        \n",
    "        if mcc_score > best_val: \n",
    "            best_val = mcc_score\n",
    "            best_threshold = f'this.rules.add(new Lesser_than_threshold(\"{feature}\", -1.0, -1.0, {float(quantile)}, 0));'\n",
    "            y_val = (test_data[feature] < quantile).astype(int)\n",
    "            val_val = f1_score(y_pred=y_val, y_true=test_data[TARGET])\n",
    "    \n",
    "    print(best_threshold)\n",
    "    #print('MCC train:', best_val)\n",
    "    #print('MCC test:', val_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, studied_file))\n",
    "test_data = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, studied_file.replace('train', 'test')))\n",
    "\n",
    "for feature in SELECTED_FEATURES: \n",
    "    best_threshold = feature\n",
    "    best_val = -2 \n",
    "    val_val = -2 \n",
    "    quantiles  = train_data[feature].quantile([i/100 for i in range(0, 101)])#train_data[feature].unique()\n",
    "    for quantile in quantiles: \n",
    "        \n",
    "        y_pred = (train_data[feature] > quantile).astype(int)\n",
    "        mcc_score = matthews_corrcoef(y_pred=y_pred, y_true=train_data[TARGET])\n",
    "        \n",
    "        if mcc_score > best_val: \n",
    "            best_val = mcc_score\n",
    "            best_threshold = f'this.rules.add(new Greater_than_threshold(\"{feature}\", -1.0, -1.0, {float(quantile)}, 0));'\n",
    "            y_val = (test_data[feature] > quantile).astype(int)\n",
    "            val_val = matthews_corrcoef(y_pred=y_val, y_true=test_data[TARGET])\n",
    "        \n",
    "        y_pred = (train_data[feature] < quantile).astype(int)\n",
    "        mcc_score = matthews_corrcoef(y_pred=y_pred, y_true=train_data[TARGET])\n",
    "        \n",
    "        if mcc_score > best_val: \n",
    "            best_val = mcc_score\n",
    "            best_threshold = f'this.rules.add(new Lesser_than_threshold(\"{feature}\", -1.0, -1.0, {float(quantile)}, 0));'\n",
    "            y_val = (test_data[feature] < quantile).astype(int)\n",
    "            val_val = matthews_corrcoef(y_pred=y_val, y_true=test_data[TARGET])\n",
    "    \n",
    "    print(best_threshold)\n",
    "    #print('MCC train:', best_val)\n",
    "    #print('MCC test:', val_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, studied_file))\n",
    "test_data = pd.read_csv(os.path.join(EXPERIMENT_DATA_PATH, studied_file.replace('train', 'test')))\n",
    "\n",
    "for feature in SELECTED_FEATURES: \n",
    "    best_threshold = feature\n",
    "    best_val = -2 \n",
    "    val_val = -2 \n",
    "    quantiles  = train_data[feature].quantile([i/100 for i in range(0, 101)])#train_data[feature].unique()\n",
    "    for quantile in quantiles: \n",
    "        \n",
    "        y_pred = (train_data[feature] > quantile).astype(int)\n",
    "        mcc_score = geometric_mean_score(y_pred=y_pred, y_true=train_data[TARGET])\n",
    "        \n",
    "        if mcc_score > best_val: \n",
    "            best_val = mcc_score\n",
    "            best_threshold = f'this.rules.add(new Greater_than_threshold(\"{feature}\", -1.0, -1.0, {float(quantile)}, 0));'\n",
    "            y_val = (test_data[feature] > quantile).astype(int)\n",
    "            val_val = geometric_mean_score(y_pred=y_val, y_true=test_data[TARGET])\n",
    "        \n",
    "        y_pred = (train_data[feature] < quantile).astype(int)\n",
    "        mcc_score = geometric_mean_score(y_pred=y_pred, y_true=train_data[TARGET])\n",
    "        \n",
    "        if mcc_score > best_val: \n",
    "            best_val = mcc_score\n",
    "            best_threshold = f'this.rules.add(new Lesser_than_threshold(\"{feature}\", -1.0, -1.0, {float(quantile)}, 0));'\n",
    "            y_val = (test_data[feature] < quantile).astype(int)\n",
    "            val_val = geometric_mean_score(y_pred=y_val, y_true=test_data[TARGET])\n",
    "    \n",
    "    print(best_threshold)\n",
    "    #print('MCC train:', best_val)\n",
    "    #print('MCC test:', val_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.sample([1, 2, 3, 4], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['algorithm', 'project_name', 'hv', 'gd']\n",
    "hv_gd_all = pd.concat([\n",
    "    pd.read_csv('C:/Users/Motaz/Desktop/work/TSE_R3/hv_gd_baselines/MEG_indicators.csv')[cols],\n",
    "    pd.read_csv('C:/Users/Motaz/Desktop/work/TSE_R3/hv_gd_baselines/MOLR_hv_GD.csv')[cols],\n",
    "    pd.read_csv('C:/Users/Motaz/Desktop/work/TSE_R3/hv_gd_baselines/MOPSO_hv_gd_CRDP.csv')[cols],\n",
    "    pd.read_csv('C:/Users/Motaz/Desktop/work/TSE_R3/hv_gd_baselines/ibea_indicators.csv')[cols]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_gd_all.to_csv(\"all_hv_gd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDP_performance_complexity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
